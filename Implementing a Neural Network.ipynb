{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sample grid for training data (code in neural.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Chempy.parameter import ModelParameters\n",
    "from Chempy.cem_function import posterior_function_returning_predictions\n",
    "from scipy.stats import norm as gaussian\n",
    "import os\n",
    "a = ModelParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This calculates a list of 5 trial values for each parameter around the prior value, as an array of 6 lists which will be combined\n",
    "# Set the desired Gaussian sigma values in the widths parameter (values > prior sigma are used to fully explore parameter space)\n",
    "# Parameter values are chosen that are evenly distributed in the Gaussian probability space (e.g. 16.7, 33, 50 etc. percentile points)\n",
    "\n",
    "N = a.training_size # No. data points per parameter\n",
    "widths = a.neural_widths # Gaussian widths for parameters\n",
    "\n",
    "# Create 1d grid of data points equally spaced in probability space \n",
    "prob = np.linspace(1/(N+1), 1-1/(N+1), N)\n",
    "grids = [gaussian.ppf(prob) for _ in range(N+1)] # Normalize to unit Gaussian\n",
    "norm_grid = np.array(np.meshgrid(*grids)).T.reshape(-1,N+1)\n",
    "\n",
    "# Create grid in parameter space\n",
    "param_grid = [item*widths+a.p0 for item in norm_grid]\n",
    "\n",
    "# Save grids\n",
    "directory = 'Neural/'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "np.save(directory+'training_norm_grid.npy',norm_grid)\n",
    "np.save(directory+'training_param_grid.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create abundance output\n",
    "#param_grid = param_grid[:6] # For testing\n",
    "training_abundances = []\n",
    "for i,item in enumerate(param_grid):\n",
    "    abundances,_ = posterior_function_returning_predictions((item,a))\n",
    "    training_abundances.append(abundances)\n",
    "    if i%100 == 0:\n",
    "        print(\"Calculating abundance set %d of %d\" %(i,len(param_grid)))\n",
    "              \n",
    "# Save abundance table\n",
    "np.save('Neural/training_abundances.npy', training_abundances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES\n",
    "\n",
    "- All code is now in neural.py file\n",
    "- Should put changeable parameters e.g. number of choices for each parameter in parameter.py file - DONE\n",
    "-  Find nicer way of using all rows from grid - DONE\n",
    "- Check whether to use Karakas 10 or Karakas 16 - Karakas 10 for testing\n",
    "- Automate number of traceable elements - just copy that from code - DONE\n",
    "\n",
    "*This may be a useful reference https://arxiv.org/abs/1502.01852, for recommendation of ReLU units, with w = np.random.randn(n) x np.sqrt(2/n) for initialized weights, from Stanford course*\n",
    "\n",
    "*Another useful reference: https://arxiv.org/abs/1412.6980 for 'Adam' learning method viz Stanford course*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ModelParameters()\n",
    "names = ['verif','test']\n",
    "#widths = a.neural_widths\n",
    "widths = a.test_widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,name in enumerate(names): # Create two identically distributed datasets\n",
    "    length = a.verif_test_sizes[i]\n",
    "    norm_grid = []\n",
    "    for _ in range(length):\n",
    "        norm_grid.append(np.random.normal(size = len(a.p0)))\n",
    "        #norm_grid = np.array(norm_grid) # IS THIS NEEDED?\n",
    "     \n",
    "    np.save(\"Neural/\"+name+\"_norm_grid.npy\",norm_grid)\n",
    "    \n",
    "    # Find the actual abundance grid\n",
    "    param_grid = [item*widths+a.p0 for item in norm_grid]\n",
    "    np.save(\"Neural/\"+name+\"_param_grid.npy\",param_grid)\n",
    "    \n",
    "    model_abundances = []\n",
    "    for j,jtem in enumerate(param_grid[:10]):\n",
    "        abundances,_ = posterior_function_returning_predictions((jtem,a))\n",
    "        model_abundances.append(abundances)\n",
    "        if j%2 == 0:\n",
    "            print(\"Calculating %s abundance set %d of %d\" %(name,j,length))\n",
    "            \n",
    "    # Save abundance table\n",
    "    np.save(\"Neural/\"+name+\"_abundances.npy\",model_abundances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(\"Neural/verif_abundances.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.hsplit(norm_grid,6)\n",
    "print(x)\n",
    "plt.hist(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
