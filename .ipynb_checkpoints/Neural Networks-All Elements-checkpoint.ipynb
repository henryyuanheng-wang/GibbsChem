{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is the code to produce a sample set for and train a neural network.**\n",
    "All python source code is in the neural.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from Chempy.parameter import ModelParameters\n",
    "a = ModelParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First create the training dataset\n",
    "from Chempy.neural import training_data\n",
    "#%timeit -r 1 -n 1 training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above was run on a faster machine, taking 2 hours, 26 minutes and 28 seconds to calculate a training dataset of length 15625. This is stored in the 'Neural/' folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now create the datasets for model verification (i.e. hyperparameter constraints)\n",
    "# and for final testing\n",
    "\n",
    "from Chempy.neural import verification_and_testing\n",
    "# %timeit -r 1 -n 1 verification_and_testing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was again run on a faster PC. The runtime was 3 hours, 19 minutes and 10 seconds, producing the verif_param_grid, verif_abundances, test_param_grid, test_abundances npy data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## The code below will allow optimization of hyperparameter\n",
    "%pylab inline\n",
    "from Chempy.parameter import ModelParameters\n",
    "a = ModelParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To plot neural network error against learning rate for optimization\n",
    "\n",
    "from Chempy.neural import create_network,neural_errors\n",
    "\n",
    "learning_rate = [0.001, 0.004, 0.007 ,0.01] #\n",
    "#learning_rate = 10**np.linspace(-4,-0.5,5)\n",
    "upper = np.zeros((len(learning_rate),1))\n",
    "lower = np.zeros((len(learning_rate),1))\n",
    "median = np.zeros((len(learning_rate),1))\n",
    "\n",
    "for i,lr in enumerate(learning_rate):\n",
    "    print(\"Creating network %d of %d\" %(i+1,len(learning_rate)))\n",
    "    create_network(learning_rate=lr,Plot=False)\n",
    "    param_error = neural_errors('verif')\n",
    "    median[i] = np.median(param_error)\n",
    "    lower[i] = np.percentile(param_error,15.865)\n",
    "    upper[i] = np.percentile(param_error,100-15.865)\n",
    " \n",
    "prin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(median)\n",
    "plt.clf()\n",
    "plt.errorbar((learning_rate),median,yerr=[median-lower,upper-median])\n",
    "plt.ylabel('Median L1 error (dex)')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.title('Optimization of Learning Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Optimal Set\n",
    "*Now using test dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now create and train the neural network for optimal hyperparameters\n",
    "%pylab inline\n",
    "from Chempy.neural import create_network\n",
    "learning_rate = 0.005\n",
    "epoch, loss = create_network(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Median error is 0.03956 - 0.02715 + 0.06268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f843caa2d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "# Create the corner plot\n",
    "%pylab inline\n",
    "from Chempy.neural import neural_corner_plot, neural_errors\n",
    "param_error = neural_errors('test')\n",
    "med = np.median(param_error)\n",
    "up = np.percentile(param_error, 100-15.865)\n",
    "low = np.percentile(param_error, 15.865)\n",
    "print('Median error is %.5f - %.5f + %.5f' %(med, med-low, up-med))\n",
    "neural_corner_plot('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat=plt.hist(param_error,bins=100)\n",
    "plt.xlabel('Median error in dex')\n",
    "plt.xlim([0.,0.05])\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram Plot for Neural Network error')\n",
    "plt.savefig('Neural/neural_hist.pdf',bbox_inches='tight',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from Chempy.neural import neural_errors,neural_output\n",
    "param_error = neural_errors('test')\n",
    "param_grid = np.load('Neural/test_param_grid.npy')\n",
    "chempy_data = np.load('Neural/test_abundances.npy')\n",
    "neural_data = []\n",
    "for i in range(len(param_grid)):\n",
    "    neural_data.append(neural_output(param_grid[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ABUNDANCE COMPARISON\n",
    "%pylab inline\n",
    "# Using first random datapoint in testset\n",
    "from Chempy.parameter import ModelParameters\n",
    "a = ModelParameters()\n",
    "# Prepare plot\n",
    "fig = plt.figure(figsize=(30.69,8.27), dpi=300)\n",
    "plt.clf()\n",
    "text_size = 15\n",
    "plt.rc('font', family='serif',size = text_size)\n",
    "plt.rc('xtick', labelsize=text_size)\n",
    "plt.rc('ytick', labelsize=text_size)\n",
    "plt.rc('axes', labelsize=text_size, lw=1.)\n",
    "plt.rc('lines', linewidth = 1.)\n",
    "plt.rcParams['ytick.major.pad']='8'\n",
    "plt.rcParams['text.latex.preamble']=[r\"\\usepackage{libertine}\"]\n",
    "params = {'text.usetex' : True,'font.size' : 16,'font.family' : 'libertine','text.latex.unicode': True}\n",
    "ax = fig.add_subplot(111)\n",
    "abundance_names = []\n",
    "proto_sun = np.load('Chempy/input/stars/Proto-sun_all.npy')\n",
    "for item in proto_sun.dtype.names[:-1]:\n",
    "    if item != 'Fe':\n",
    "        abundance_names.append('[%s/Fe]' %(item))\n",
    "    else:\n",
    "        abundance_names.append('[Fe/H]')\n",
    "plt.xticks(np.arange(len(a.element_names)),abundance_names)\n",
    "\n",
    "sol_dat = np.load('Chempy/input/stars/Proto-sun_all.npy')\n",
    "abun = []\n",
    "err = []\n",
    "for i in range(len(sol_dat[0])-1):\n",
    "    abun.append(sol_dat[0][i])\n",
    "    err.append(sol_dat[1][i])\n",
    "plt.plot(neural_data[0],'r',label='Neural')\n",
    "plt.plot(chempy_data[0],'g',label='Chempy')\n",
    "plt.errorbar(np.arange(len(abun)),abun,yerr=err,label='Proto-Solar')\n",
    "plt.legend()\n",
    "plt.ylabel(\"Abundances relative to solar in dex\")\n",
    "plt.xlabel(\"Element\")\n",
    "plt.title(\"Abundance plot for parameters %s\" %(param_grid[0]))\n",
    "#savefig('Neural/neural_abundances',bbox_inches='tight')\n",
    "savefig('Pres/neural_abundances',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTES / TO DO (see other file also)**\n",
    "- *Change the diagonal to be correct histogram of data - DONE*\n",
    "- *Color histogram by mean error in that bar - DONE*\n",
    "- *Add other params - DONE*\n",
    "- *Sort axis names - DONE*\n",
    "- *SORT axis sizes (see plot_mcmc.py) - DONE*\n",
    "- *Vectorize neural output calculation - probably not necessary*\n",
    "- *Add support for corner plot to take either dataset - DONE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Chempy.neural import neural_output\n",
    "param = [-3.,-3.,-0.8,-0.5,0.5,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(neural_output(param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coeffs = np.load('Neural/neural_model.npz')\n",
    "w_array_0 = coeffs['w_array_0']\n",
    "w_array_1 = coeffs['w_array_1']\n",
    "b_array_0 = coeffs['b_array_0']\n",
    "b_array_1 = coeffs['b_array_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_array_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_output = np.load('Neural/training_abundances.npy')\t\n",
    "\n",
    "# Calculate the model dimensions\n",
    "dim_out = tr_output.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
