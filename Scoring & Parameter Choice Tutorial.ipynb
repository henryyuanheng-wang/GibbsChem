{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tutorial contents**:\n",
    "- Adding new yield tables\n",
    "- Choosing element set\n",
    "- Training of a neural network\n",
    "- Running MCMC analysis\n",
    "- Computing Bayes/LOO-CV scores\n",
    "\n",
    "The above are based on the Philcox & Rybizki (2017) paper which should be cited when using this code. This is based on the $\\mathit{Chempy}$ software, described in Rybizki et al. (2017, arXiv:1702.08729) and full tutorials for this can be found at https://github.com/jan-rybizki/Chempy/tree/master/tutorials.\n",
    "\n",
    "** Requirements**:\n",
    "Before running this tutorial, the $\\mathit{ChempyScoring}$ code and its dependencies must be installed (https://github.com/oliverphilcox/ChempyScoring/blob/master/requirements.txt)\n",
    "\n",
    "The authors Oliver Philcox (ohep2@cam.ac.uk) and Jan Rybizki (rybizki@mpia.de) are happy to assist with any problems which may arise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Yield Tables - ADD TABLE\n",
    "\n",
    "First we must load in the Nucleosynthetic yield table to be tested. Here we will test the SN2 net yields of Frischknecht et al. (2016, arXiv:1511.05730). These include s-process elements for stars of mass 15-40Msun, with rotation. Here we implement the yield tables for standard rotation and differing metallicities.\n",
    "\n",
    "The yield tables provide data for masses 15,20,25,40 Msun, metalicities of solar (0.0134), 0.001, 1e-5 and 1e-7 and differing stellar rotation speeds. Here we only use solar, 0.001 and 1e-5 metallicities and standard rotations, since only these have data for all masses. \n",
    "\n",
    "To add this into *Chempy* we add a `Frischknecht16_net` function to the `SN2_feedback()` class in `yields.py` as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NB: The Frischknecht16 definition should be inserted into the yields.py file\n",
    "\n",
    "from Chempy import localpath # For file locations\n",
    "import numpy as np\n",
    "\n",
    "class SN2_feedback(object):\n",
    "    def __init__(self):   \n",
    "        \"\"\"\n",
    "        This is the object that holds the feedback table for SN2 stars.\n",
    "                The different methods load different tables from the literature. They are in the input/yields/ folder.\n",
    "        \"\"\"\n",
    "\n",
    "    def Frischknecht16_net(self):\n",
    "        \"\"\"SN2 yields from Frischknecht et al. 2016. These are implemented for masses of 15-40Msun, for rotating stars.\n",
    "        Yields from stars with 'normal' rotations are used here.\n",
    "        These are net yields automatically, so no conversions need to be made\n",
    "        \"\"\"\n",
    "        import numpy.lib.recfunctions as rcfuncs\n",
    "        import os\n",
    "\n",
    "        # Define metallicites \n",
    "        self.metallicities = [0.0134,1e-3,1e-5] # First is solar value\n",
    "\n",
    "        # Define masses\n",
    "        self.masses=  np.array((15,20,25,40))\n",
    "\n",
    "        # Load yield table dictionary in correct format from npy file if it exists\n",
    "        saved_yields = localpath+'input/yields/Frischknecht16_net.npy'\n",
    "        if os.path.exists(saved_yields):\n",
    "            self.table = np.load(saved_yields).item()\n",
    "\n",
    "        else:\n",
    "            # If not, create yield table from .txt file\n",
    "\n",
    "            # Define data types\n",
    "            dt = np.dtype('U8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8,f8')\n",
    "\n",
    "            # Initialise yield table\n",
    "            yield_table = {}\n",
    "\n",
    "\n",
    "            # Import full table with correct rows and data-types\n",
    "            z = np.genfromtxt(localpath+'input/yields/Frischknecht16/yields_total.txt',skip_header=62,dtype=dt)\n",
    "\n",
    "            # Define isotope indexing. For radioactive isotopes with half-lives << Chempy time_step they are assigned to their daughter element\n",
    "            # NB: we only use elements up to Ge here, as in the paper\n",
    "            indexing={}\n",
    "            indexing['H']=['p','d']\n",
    "            indexing['He'] = ['he3','he4']\n",
    "            indexing['Li'] = ['li6','li7']\n",
    "            indexing['Be']  = ['be9']\n",
    "            indexing['B']  = ['b10','b11']\n",
    "            indexing['C']  = ['c12','c13']\n",
    "            indexing['N']  = ['n14','n15']\n",
    "            indexing['O']  = ['o16','o17','o18']\n",
    "            indexing['F']  = ['f19']\n",
    "            indexing['Ne']  = ['ne20','ne21','ne22']\n",
    "            indexing['Na']  = ['na23']\n",
    "            indexing['Mg']  = ['mg24','mg25','mg26','al26']\n",
    "            indexing['Al']  = ['al27']\n",
    "            indexing['Si']  = ['si28','si29','si30']\n",
    "            indexing['P']  = ['p31']\n",
    "            indexing['S']  = ['s32','s33','s34','s36']\n",
    "            indexing['Cl']  = ['cl35','cl37']\n",
    "            indexing['Ar']  = ['ar36','ar38','ar40']\n",
    "            indexing['K']  = ['k39','k41']\n",
    "            indexing['Ca']  = ['ca40','ca42','ca43','ca44','ca46','ca48']\n",
    "            indexing['Sc']  = ['sc45']\n",
    "            indexing['Ti']  = ['ti46','ti47','ti48','ti49','ti50']\n",
    "            indexing['V']  = ['v50','v51']\n",
    "            indexing['Cr']  = ['cr50','cr52','cr53','cr54']\n",
    "            indexing['Mn']  = ['mn55']\n",
    "            indexing['Fe']  = ['fe54', 'fe56','fe57','fe58']\n",
    "            indexing['Co']  = ['fe60', 'co59']\n",
    "            indexing['Ni']  = ['ni58','ni60','ni61','ni62','ni64']\n",
    "            indexing['Cu']  = ['cu63','cu65']\n",
    "            indexing['Zn']  = ['zn64','zn66','zn67','zn68','zn70']\n",
    "            indexing['Ga']  = ['ga69','ga71']\n",
    "            indexing['Ge']  = ['ge70','ge72','ge73','ge74','ge76']\n",
    "\n",
    "            # Define indexed elements \n",
    "            self.elements = list(indexing.keys())\n",
    "\n",
    "            # Create model dictionary indexed by metallicity, giving relevant model number for each choice of mass\n",
    "            # See Frischknecht info_yields.txt file for model information\n",
    "            model_dict = {}\n",
    "            model_dict[0.0134] = [2,8,14,27]\n",
    "            model_dict[1e-3]=[4,10,16,28]\n",
    "            model_dict[1e-5]=[6,12,18,29]\n",
    "\n",
    "            # Import list of remnant masses for each model (from row 32-60, column 6 of .txt file) \n",
    "            # NB: these are in solar masses\n",
    "            rem_mass_table = np.loadtxt(localpath+'input/yields/Frischknecht16/yields_total.txt',skiprows=31,usecols=6)[:29]\n",
    "\n",
    "            # Create one subtable for each metallicity \n",
    "            for metallicity in self.metallicities:\n",
    "                additional_keys = ['Mass', 'mass_in_remnants','unprocessed_mass_in_winds'] # List of keys for table\n",
    "                names = additional_keys + self.elements\n",
    "\n",
    "                # Initialise table and arrays   \n",
    "                base = np.zeros(len(self.masses))\n",
    "                list_of_arrays = []\n",
    "                for i in range(len(names)):\n",
    "                    list_of_arrays.append(base)\n",
    "                yield_subtable = np.core.records.fromarrays(list_of_arrays,names=names)\n",
    "                mass_in_remnants = np.zeros(len(self.masses))\n",
    "                total_mass_fraction = np.zeros(len(self.masses))\n",
    "                element_mass = np.zeros(len(self.masses))\n",
    "\n",
    "                # Add masses to table\n",
    "                yield_subtable['Mass'] = self.masses\n",
    "\n",
    "\n",
    "                # Extract remnant masses (in solar masses) for each model:\n",
    "                for mass_index,model_index in enumerate(model_dict[metallicity]):\n",
    "                    mass_in_remnants[mass_index] = rem_mass_table[model_index-1] \n",
    "\n",
    "               # Iterate over all elements \n",
    "                for element in self.elements:\n",
    "                    element_mass = np.zeros(len(self.masses))\n",
    "                    for isotope in indexing[element]: # Iterate over isotopes of each element\n",
    "                        for mass_index,model_index in enumerate(model_dict[metallicity]): # Iterate over masses \n",
    "                            for row in z: # Find required row in table \n",
    "                                if row[0] == isotope:\n",
    "                                    element_mass[mass_index]+=row[model_index] # Compute cumulative mass for all isotopes\n",
    "                    yield_subtable[element]=element_mass # Add entry to subtable\n",
    "\n",
    "                all_fractions = [row[model_index] for row in z] # This lists all elements (not just up to Ge)\n",
    "                total_mass_fraction[mass_index] = np.sum(all_fractions) # Compute total net mass fraction (sums to approximately 0)\n",
    "\n",
    "                # Add fields for remnant mass (now as a mass fraction) and unprocessed mass fraction\n",
    "                yield_subtable['mass_in_remnants']=np.divide(mass_in_remnants,self.masses)                    \n",
    "                yield_subtable['unprocessed_mass_in_winds'] = 1.-(yield_subtable['mass_in_remnants']+total_mass_fraction) # This is all mass not from yields/remnants\n",
    "\n",
    "                # Add subtable to full table\n",
    "                yield_table[metallicity]=yield_subtable\n",
    "\n",
    "            # Define final yield table for output\n",
    "            self.table = yield_table\n",
    "\n",
    "            # Save yield table to avoid reloading each time\n",
    "            np.save(saved_yields,self.table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now test the new yield table (using Ca as an example element):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ca Yields\n",
      "\n",
      " Metallicity = 1.34e-02\n",
      "Mass = 15, Yield  = -4.661234e-05\n",
      "Mass = 20, Yield  = -1.013723e-04\n",
      "Mass = 25, Yield  = -1.498169e-04\n",
      "Mass = 40, Yield  = -3.603430e-04\n",
      "\n",
      " Metallicity = 1.00e-03\n",
      "Mass = 15, Yield  = -2.467764e-06\n",
      "Mass = 20, Yield  = -4.861126e-06\n",
      "Mass = 25, Yield  = -8.312735e-06\n",
      "Mass = 40, Yield  = -1.565401e-05\n",
      "\n",
      " Metallicity = 1.00e-05\n",
      "Mass = 15, Yield  = -2.234603e-08\n",
      "Mass = 20, Yield  = -4.682224e-08\n",
      "Mass = 25, Yield  = -6.924936e-08\n",
      "Mass = 40, Yield  = -1.481142e-07\n"
     ]
    }
   ],
   "source": [
    "# Define correct yield table\n",
    "from Chempy.wrapper import SN2_feedback\n",
    "basic_sn2 = SN2_feedback()\n",
    "getattr(basic_sn2, 'Frischknecht16_net')()\n",
    "\n",
    "print(\"Ca Yields\")\n",
    "for metallicity in basic_sn2.metallicities:\n",
    "    print(\"\\n Metallicity = %.2e\" %(metallicity))\n",
    "    for i in range(len(basic_sn2.masses)):\n",
    "        print(\"Mass = %d, Yield  = %.6e\" %(basic_sn2.masses[i],basic_sn2.table[metallicity]['Ca'][i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -8.71712663e-10,  -1.17302861e-09,  -1.90546586e-09,\n",
       "        -2.32895755e-09])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_sn2.table[1e-3]['B']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Choice of Elements\n",
    "\n",
    "We are free to use any set of chemical elements in this analysis. The set should be chosen to match the simulation. 28 elements up to Ge (excluding Li, B, Be) and the IllustrisTNG elements (Pillepich et al. 2017) were used in the Philcox & Rybizki 2017 paper.\n",
    "\n",
    "To select the required elements we modify the `Chempy/parameter.py` file.\n",
    "\n",
    "Both `elements_to_trace` **and** `initial_neural_names` must be changed here.\n",
    "\n",
    "\n",
    "*`elements_to_trace` contains elements in the proto-solar data-file, including B, Be, Li and H which are not predicted directly by the neural network. `initial_neural_names` is the elements predicted by the network only (as [X/Fe] or [Fe/H] abundances.*\n",
    "\n",
    "In addition, if extra elements are added, it should be checked that they are predicted by the yield tables and feature in the `Chempy/input/stars/proto_sun_all.npy` observational data-set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Modify these lines in Chempy/parameter.py\n",
    "\n",
    "# This field should contain all required elements  (and B,Be,Li,H) in alphabetical order\n",
    "elements_to_trace = ['Al', 'Ar', 'B', 'Be', 'C', 'Ca', 'Cl', 'Co', 'Cr', 'Cu', 'F', 'Fe', 'Ga', 'Ge', 'H', 'He', 'K', 'Li', 'Mg', 'Mn', 'N', 'Na', 'Ne', 'Ni', 'O', 'P', 'S', 'Sc', 'Si', 'Ti', 'V', 'Zn']\n",
    "\n",
    "# This field contains names of elements predicted by neural network\n",
    "initial_neural_names = ['Al', 'Ar', 'C', 'Ca', 'Cl', 'Co', 'Cr', 'Cu', 'F', 'Fe', 'Ga', 'Ge', 'He', 'K', 'Mg', 'Mn', 'N', 'Na', 'Ne', 'Ni', 'O', 'P', 'S', 'Sc', 'Si', 'Ti', 'V', 'Zn']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Neural Network Dataset\n",
    "\n",
    "Now that the yield set has been implemented, we must next create a training data-set for the neural network.\n",
    "\n",
    "Firstly it is important to change the `parameter.py` file such that *Chempy* uses the correct yields. Here we add the new SN2 yield table name and set *Chempy* to use it by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Modify these lines in Chempy/parameter.py to add new yield set\n",
    "yield_table_name_sn2_list = ['chieffi04','Nugrid','Nomoto2013','Portinari', 'chieffi04_net', 'Nomoto2013_net','NuGrid_net','West17_net','TNG_net']#'Frischknecht16_net'\n",
    "yield_table_name_sn2_index = 7\n",
    "yield_table_name_sn2 = yield_table_name_sn2_list[yield_table_name_sn2_index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "West17_net\n"
     ]
    }
   ],
   "source": [
    "# Load parameter file\n",
    "from Chempy.parameter import ModelParameters\n",
    "a = ModelParameters()\n",
    "\n",
    "# Print new SN2 yield table name\n",
    "print(a.yield_table_name_sn2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must also set the list of parameters to optimize over to include only the 5 free *Chempy* parameters (i.e. not $\\beta$). This will be changed later in the analysis, but must be done at this point, else the `training_data()` routine will fail. \n",
    "\n",
    "**Here we can also change the free parameters **\n",
    "\n",
    "For compatibility reasons $\\beta$ (when later added) is included in the SSP_parameters definition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modify these lines in Chempy/parameter.py file\n",
    "\n",
    "SSP_parameters =  [-2.29,-2.75]\n",
    "SSP_parameters_to_optimize = ['high_mass_slope','log10_N_0']\n",
    "assert len(SSP_parameters) == len(SSP_parameters_to_optimize)\n",
    "\n",
    "ISM_parameters =  [-0.3,0.55,0.5]\n",
    "ISM_parameters_to_optimize = ['log10_starformation_efficiency', 'log10_sfr_scale', 'outflow_feedback_fraction']\n",
    "assert len(ISM_parameters) == len(ISM_parameters_to_optimize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must also turn OFF the neural network predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Chempy/parameter.py\n",
    "UseNeural=False\n",
    "\n",
    "# To test\n",
    "a.UseNeural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data-sets can be created using the `Chempy.neural` module as follows and are saved in the `Neural/` directory. \n",
    "\n",
    "This uses multiprocessing to create a training data-set using 10 values of each of the 5 free *Chempy* parameters. (This value can be changed using `training_size` in `parameter.py`). These are written to file as `Neural/training_abundances.npy` (abundance output) and `Neural/training_norm_grid.npy` (normalised input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Chempy.neural import training_data\n",
    "#training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above was run on a 64-core machine, taking 45 minutes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we must train the neural network using the previously constructed data-sets. This can be simply done with the `Chempy/neural.py` `create_network()` function. This creates and trains a 30-neuron network over 1000 training epochs, using a learning rate of 0.007 by default (optimised via a validation data-set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Chempy.neural import create_network\n",
    "#create_network(Plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above was run on an 8-core machine taking 20 minutes. The trained network is saved as `Neural/neural_model.npz`. A loss plot is also produced, showing the network loss function against training epoch (if `Plot=True`).\n",
    "\n",
    "Using `Chempy/neural.py`'s `neural_output()` function we may simulate the output of *Chempy* for any set of input parameters;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element \t Predicted abundance\n",
      "------------------------------------\n",
      "Al \t\t -0.316759824738\n",
      "Ar \t\t 0.312959080369\n",
      "C \t\t -0.266671754526\n",
      "Ca \t\t -0.525946020995\n",
      "Cl \t\t -0.101032700348\n",
      "Co \t\t -0.363575246299\n",
      "Cr \t\t -0.305827662797\n",
      "Cu \t\t 0.0580966357488\n"
     ]
    }
   ],
   "source": [
    "from Chempy.parameter import ModelParameters\n",
    "a = ModelParameters()\n",
    "\n",
    "from Chempy.neural import neural_output\n",
    "\n",
    "# Here we compute the neural network predictions for the prior values of the free parameters (a.p0) \n",
    "output = neural_output(a.p0)\n",
    "\n",
    "print(\"Element \\t Predicted abundance\")\n",
    "print(\"------------------------------------\")\n",
    "for i in range(len(output)):\n",
    "    print(a.initial_neural_names[i],\"\\t\\t\",output[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Run MCMC analysis\n",
    "\n",
    "We can now run MCMC on the yield set and produce optimal parameters and a corner plot. This is done as shown below, using a trained neural network.\n",
    "\n",
    "Whichever neural network is in the `Neural/` directory will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Proto-sun_all']\n",
      "first minimization for each star separately took:  0 seconds\n",
      "step  1 of  1000\n",
      "1.73569619634 1.7353424002\n",
      "calculation so far took 1.6636462211608887  seconds\n",
      "step  2 of  1000\n",
      "1.73569619634 1.73446346283\n",
      "calculation so far took 1.9948980808258057  seconds\n",
      "step  3 of  1000\n",
      "1.73569619634 1.73111670318\n",
      "calculation so far took 2.3175220489501953  seconds\n",
      "step  4 of  1000\n",
      "1.73569619634 1.72968438599\n",
      "calculation so far took 2.7558858394622803  seconds\n",
      "step  5 of  1000\n",
      "1.73569619634 1.72378296961\n",
      "calculation so far took 3.1382975578308105  seconds\n",
      "step  6 of  1000\n",
      "1.73569619634 1.70758419918\n",
      "calculation so far took 3.51373291015625  seconds\n",
      "step  7 of  1000\n",
      "1.73569619634 1.69546069415\n",
      "calculation so far took 3.8425889015197754  seconds\n",
      "step  8 of  1000\n",
      "1.73569619634 1.65553515173\n",
      "calculation so far took 4.18914532661438  seconds\n",
      "step  9 of  1000\n",
      "1.73569619634 1.6015698814\n",
      "calculation so far took 4.543027877807617  seconds\n",
      "step  10 of  1000\n",
      "1.73569619634 1.46826507008\n",
      "calculation so far took 4.882636785507202  seconds\n",
      "step  11 of  1000\n",
      "1.73569619634 1.35694110383\n",
      "calculation so far took 5.22933030128479  seconds\n",
      "step  12 of  1000\n",
      "1.73569619634 1.16549675827\n",
      "calculation so far took 5.564008712768555  seconds\n",
      "step  13 of  1000\n",
      "1.73569619634 0.976467775835\n",
      "calculation so far took 5.896732807159424  seconds\n",
      "step  14 of  1000\n",
      "1.73569619634 0.866212175678\n",
      "calculation so far took 6.236514091491699  seconds\n",
      "step  15 of  1000\n",
      "1.73569619634 0.652283482647\n",
      "calculation so far took 6.585185766220093  seconds\n",
      "step  16 of  1000\n",
      "1.73569619634 0.406826964624\n",
      "calculation so far took 6.92892050743103  seconds\n",
      "step  17 of  1000\n",
      "1.73569619634 0.173800438012\n",
      "calculation so far took 7.2573158740997314  seconds\n",
      "step  18 of  1000\n",
      "1.73569619634 0.17283841556\n",
      "calculation so far took 7.636943101882935  seconds\n",
      "step  19 of  1000\n",
      "1.73569619634 0.149859086668\n",
      "calculation so far took 7.977421045303345  seconds\n",
      "step  20 of  1000\n",
      "1.73569619634 -0.0544180618515\n",
      "calculation so far took 8.327783823013306  seconds\n",
      "step  21 of  1000\n",
      "1.73569619634 -0.148595985837\n",
      "calculation so far took 8.724821329116821  seconds\n",
      "step  22 of  1000\n",
      "1.73569619634 -0.105697040269\n",
      "calculation so far took 9.067442417144775  seconds\n",
      "step  23 of  1000\n",
      "1.73569619634 -0.125303988053\n",
      "calculation so far took 9.404237985610962  seconds\n",
      "step  24 of  1000\n",
      "1.73569619634 -0.029630241122\n",
      "calculation so far took 9.746306419372559  seconds\n",
      "step  25 of  1000\n",
      "1.73569619634 -0.13472929796\n",
      "calculation so far took 10.086540460586548  seconds\n",
      "step  26 of  1000\n",
      "1.73569619634 -0.277585488693\n",
      "calculation so far took 10.448867797851562  seconds\n",
      "step  27 of  1000\n",
      "1.73569619634 -0.0014465503665\n",
      "calculation so far took 10.761712312698364  seconds\n",
      "step  28 of  1000\n",
      "1.73569619634 0.0776588014439\n",
      "calculation so far took 11.086379289627075  seconds\n",
      "step  29 of  1000\n",
      "1.73569619634 0.0713833466739\n",
      "calculation so far took 11.46093201637268  seconds\n",
      "step  30 of  1000\n",
      "1.73569619634 -0.13563171573\n",
      "calculation so far took 11.774333477020264  seconds\n",
      "step  31 of  1000\n",
      "1.73569619634 0.0349492087271\n",
      "calculation so far took 12.14180040359497  seconds\n",
      "step  32 of  1000\n",
      "1.73569619634 0.241255804532\n",
      "calculation so far took 12.490000486373901  seconds\n",
      "step  33 of  1000\n",
      "1.73569619634 0.159997876337\n",
      "calculation so far took 12.847141027450562  seconds\n",
      "step  34 of  1000\n",
      "1.73569619634 0.00125956532002\n",
      "calculation so far took 13.17006778717041  seconds\n",
      "step  35 of  1000\n",
      "1.73569619634 -0.125277203275\n",
      "calculation so far took 13.488613605499268  seconds\n",
      "step  36 of  1000\n",
      "1.73569619634 -0.0430328466423\n",
      "calculation so far took 13.807525157928467  seconds\n",
      "step  37 of  1000\n",
      "1.73569619634 0.131972071127\n",
      "calculation so far took 14.125734806060791  seconds\n",
      "step  38 of  1000\n",
      "1.73569619634 0.148303386246\n",
      "calculation so far took 14.445806503295898  seconds\n",
      "step  39 of  1000\n",
      "1.73569619634 0.222895575841\n",
      "calculation so far took 14.764621019363403  seconds\n",
      "step  40 of  1000\n",
      "1.73569619634 0.319871235456\n",
      "calculation so far took 15.08271861076355  seconds\n",
      "step  41 of  1000\n",
      "1.73569619634 0.228824724824\n",
      "calculation so far took 15.400267124176025  seconds\n",
      "step  42 of  1000\n",
      "1.73569619634 0.0745199797519\n",
      "calculation so far took 15.711856126785278  seconds\n",
      "step  43 of  1000\n",
      "1.73569619634 0.0418945292905\n",
      "calculation so far took 16.025784969329834  seconds\n",
      "step  44 of  1000\n",
      "1.73569619634 -0.000301485057493\n",
      "calculation so far took 16.349934339523315  seconds\n",
      "step  45 of  1000\n",
      "1.73569619634 -0.0736554668546\n",
      "calculation so far took 16.67335319519043  seconds\n",
      "step  46 of  1000\n",
      "1.73569619634 0.00788678628929\n",
      "calculation so far took 16.992005825042725  seconds\n",
      "step  47 of  1000\n",
      "1.73569619634 0.234179345812\n",
      "calculation so far took 17.30999779701233  seconds\n",
      "step  48 of  1000\n",
      "1.73569619634 0.139565699382\n",
      "calculation so far took 17.62878966331482  seconds\n",
      "step  49 of  1000\n",
      "1.73569619634 0.222202267968\n",
      "calculation so far took 17.961509227752686  seconds\n",
      "step  50 of  1000\n",
      "1.73569619634 0.119952036669\n",
      "calculation so far took 18.336601972579956  seconds\n",
      "step  51 of  1000\n",
      "1.73569619634 0.0118870501171\n",
      "calculation so far took 18.654273509979248  seconds\n",
      "step  52 of  1000\n",
      "1.73569619634 0.0932402104763\n",
      "calculation so far took 18.969533681869507  seconds\n",
      "step  53 of  1000\n",
      "1.73569619634 0.0822635888028\n",
      "calculation so far took 19.305318593978882  seconds\n",
      "step  54 of  1000\n",
      "1.73569619634 0.0620173613476\n",
      "calculation so far took 19.657573699951172  seconds\n",
      "step  55 of  1000\n",
      "1.73569619634 0.13790055487\n",
      "calculation so far took 20.01483654975891  seconds\n",
      "step  56 of  1000\n",
      "1.73569619634 0.116314783241\n",
      "calculation so far took 20.361461400985718  seconds\n",
      "step  57 of  1000\n",
      "1.73569619634 0.122871668152\n",
      "calculation so far took 20.70502018928528  seconds\n",
      "step  58 of  1000\n",
      "1.73569619634 0.0890008885466\n",
      "calculation so far took 21.035707235336304  seconds\n",
      "step  59 of  1000\n",
      "1.73569619634 0.0867910543009\n",
      "calculation so far took 21.38335371017456  seconds\n",
      "step  60 of  1000\n",
      "1.73569619634 0.248940028742\n",
      "calculation so far took 21.71895408630371  seconds\n",
      "step  61 of  1000\n",
      "1.73569619634 0.168164818396\n",
      "calculation so far took 22.044995069503784  seconds\n",
      "step  62 of  1000\n",
      "1.73569619634 0.27733237375\n",
      "calculation so far took 22.371198177337646  seconds\n",
      "step  63 of  1000\n",
      "1.73569619634 0.266946245583\n",
      "calculation so far took 22.730146884918213  seconds\n",
      "step  64 of  1000\n",
      "1.73569619634 0.209993811328\n",
      "calculation so far took 23.057295322418213  seconds\n",
      "step  65 of  1000\n",
      "1.73569619634 0.0836975202524\n",
      "calculation so far took 23.402555227279663  seconds\n",
      "step  66 of  1000\n",
      "1.73569619634 0.273818836158\n",
      "calculation so far took 23.738945245742798  seconds\n",
      "step  67 of  1000\n",
      "1.73569619634 0.313705550879\n",
      "calculation so far took 24.07705283164978  seconds\n",
      "step  68 of  1000\n",
      "1.73569619634 0.3183491788\n",
      "calculation so far took 24.420584440231323  seconds\n",
      "step  69 of  1000\n",
      "1.73569619634 0.358956304011\n",
      "calculation so far took 24.759622812271118  seconds\n",
      "step  70 of  1000\n",
      "1.73569619634 0.272703982128\n",
      "calculation so far took 25.081368923187256  seconds\n",
      "step  71 of  1000\n",
      "1.73569619634 0.0919081947842\n",
      "calculation so far took 25.410457134246826  seconds\n",
      "step  72 of  1000\n",
      "1.73569619634 0.263687117701\n",
      "calculation so far took 25.772979021072388  seconds\n",
      "step  73 of  1000\n",
      "1.73569619634 0.538857494555\n",
      "calculation so far took 26.127368927001953  seconds\n",
      "step  74 of  1000\n",
      "1.73569619634 0.55615158617\n",
      "calculation so far took 26.46034264564514  seconds\n",
      "step  75 of  1000\n",
      "1.73569619634 0.643937137627\n",
      "calculation so far took 26.794780254364014  seconds\n",
      "step  76 of  1000\n",
      "1.73569619634 0.570143883549\n",
      "calculation so far took 27.14078164100647  seconds\n",
      "step  77 of  1000\n",
      "1.73569619634 0.69319930809\n",
      "calculation so far took 27.463920831680298  seconds\n",
      "step  78 of  1000\n",
      "1.73569619634 0.669044147465\n",
      "calculation so far took 27.783538103103638  seconds\n",
      "step  79 of  1000\n",
      "1.73569619634 0.803151927519\n",
      "calculation so far took 28.144529581069946  seconds\n",
      "step  80 of  1000\n",
      "1.73569619634 0.780658361529\n",
      "calculation so far took 28.461146354675293  seconds\n",
      "step  81 of  1000\n",
      "1.73569619634 0.856221552216\n",
      "calculation so far took 28.79369616508484  seconds\n",
      "step  82 of  1000\n",
      "1.73569619634 0.861075019353\n",
      "calculation so far took 29.133079051971436  seconds\n",
      "step  83 of  1000\n",
      "1.73569619634 0.897797648195\n",
      "calculation so far took 29.492960929870605  seconds\n",
      "step  84 of  1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.73569619634 0.874550862019\n",
      "calculation so far took 29.829168558120728  seconds\n",
      "step  85 of  1000\n",
      "1.73569619634 0.747898520289\n",
      "calculation so far took 30.166311502456665  seconds\n",
      "step  86 of  1000\n",
      "1.73569619634 0.500359910389\n",
      "calculation so far took 30.47402048110962  seconds\n",
      "step  87 of  1000\n",
      "1.73569619634 0.3047447488\n",
      "calculation so far took 30.782214641571045  seconds\n",
      "step  88 of  1000\n",
      "1.73569619634 0.324448250287\n",
      "calculation so far took 31.093920946121216  seconds\n",
      "step  89 of  1000\n",
      "1.73569619634 0.344398696378\n",
      "calculation so far took 31.416279077529907  seconds\n",
      "step  90 of  1000\n",
      "1.73569619634 0.416643162612\n",
      "calculation so far took 31.729092597961426  seconds\n",
      "step  91 of  1000\n",
      "1.73569619634 0.591688326557\n",
      "calculation so far took 32.045167446136475  seconds\n",
      "step  92 of  1000\n",
      "1.73569619634 0.71952873252\n",
      "calculation so far took 32.35832142829895  seconds\n",
      "step  93 of  1000\n",
      "1.73569619634 0.673198820489\n",
      "calculation so far took 32.67647385597229  seconds\n",
      "step  94 of  1000\n",
      "1.73569619634 0.647988457665\n",
      "calculation so far took 32.98983311653137  seconds\n",
      "step  95 of  1000\n",
      "1.73569619634 0.587528298719\n",
      "calculation so far took 33.35493755340576  seconds\n",
      "step  96 of  1000\n",
      "1.73569619634 0.795893240538\n",
      "calculation so far took 33.69364547729492  seconds\n",
      "step  97 of  1000\n",
      "1.73569619634 0.820935913682\n",
      "calculation so far took 34.01969075202942  seconds\n",
      "step  98 of  1000\n",
      "1.73569619634 0.932157038674\n",
      "calculation so far took 34.35991859436035  seconds\n",
      "step  99 of  1000\n",
      "1.73569619634 0.894931366941\n",
      "calculation so far took 34.69027233123779  seconds\n",
      "step  100 of  1000\n",
      "1.73569619634 0.968740592202\n",
      "calculation so far took 35.04578876495361  seconds\n",
      "step  101 of  1000\n",
      "1.73569619634 0.878059511751\n",
      "calculation so far took 35.37567949295044  seconds\n",
      "step  102 of  1000\n",
      "1.73569619634 1.0122505053\n",
      "calculation so far took 35.708444595336914  seconds\n",
      "step  103 of  1000\n",
      "1.73569619634 0.725690290155\n",
      "calculation so far took 36.054014682769775  seconds\n",
      "step  104 of  1000\n",
      "1.73569619634 0.656964010038\n",
      "calculation so far took 36.38037323951721  seconds\n",
      "step  105 of  1000\n",
      "1.73569619634 0.563562735336\n",
      "calculation so far took 36.71857213973999  seconds\n",
      "step  106 of  1000\n",
      "1.73569619634 0.635824870392\n",
      "calculation so far took 37.04538130760193  seconds\n",
      "step  107 of  1000\n",
      "1.73569619634 0.556508868063\n",
      "calculation so far took 37.37927484512329  seconds\n",
      "step  108 of  1000\n",
      "1.73569619634 0.77050875362\n",
      "calculation so far took 37.71804213523865  seconds\n",
      "step  109 of  1000\n",
      "1.73569619634 0.584902311907\n",
      "calculation so far took 38.04024267196655  seconds\n",
      "step  110 of  1000\n",
      "1.73569619634 0.610469158895\n",
      "calculation so far took 38.35862922668457  seconds\n",
      "step  111 of  1000\n",
      "1.73569619634 0.66401428401\n",
      "calculation so far took 38.69697380065918  seconds\n",
      "step  112 of  1000\n",
      "1.73569619634 0.58352506309\n",
      "calculation so far took 39.039602518081665  seconds\n",
      "step  113 of  1000\n",
      "1.73569619634 0.681992787536\n",
      "calculation so far took 39.364182472229004  seconds\n",
      "step  114 of  1000\n",
      "1.73569619634 0.773759818987\n",
      "calculation so far took 39.68539476394653  seconds\n",
      "step  115 of  1000\n",
      "1.73569619634 0.631636067085\n",
      "calculation so far took 40.00442671775818  seconds\n",
      "step  116 of  1000\n",
      "1.73569619634 0.613038798127\n",
      "calculation so far took 40.363194704055786  seconds\n",
      "step  117 of  1000\n",
      "1.73569619634 0.661640098063\n",
      "calculation so far took 40.6845178604126  seconds\n",
      "step  118 of  1000\n",
      "1.73569619634 0.793591360993\n",
      "calculation so far took 41.00709080696106  seconds\n",
      "step  119 of  1000\n",
      "1.73569619634 0.863527424196\n",
      "calculation so far took 41.355709075927734  seconds\n",
      "step  120 of  1000\n",
      "1.73569619634 0.826382429937\n",
      "calculation so far took 41.69381618499756  seconds\n",
      "step  121 of  1000\n",
      "1.73569619634 0.738815513941\n",
      "calculation so far took 42.08578634262085  seconds\n",
      "step  122 of  1000\n",
      "1.73569619634 0.896378881998\n",
      "calculation so far took 42.42088723182678  seconds\n",
      "step  123 of  1000\n",
      "1.73569619634 0.861067347079\n",
      "calculation so far took 42.74756860733032  seconds\n",
      "step  124 of  1000\n",
      "1.73569619634 0.823637721435\n",
      "calculation so far took 43.096728563308716  seconds\n",
      "step  125 of  1000\n",
      "1.73569619634 0.772114998863\n",
      "calculation so far took 43.45469641685486  seconds\n",
      "step  126 of  1000\n",
      "1.73569619634 0.703236482917\n",
      "calculation so far took 43.78183341026306  seconds\n",
      "step  127 of  1000\n",
      "1.73569619634 0.588305042766\n",
      "calculation so far took 44.10550832748413  seconds\n",
      "step  128 of  1000\n",
      "1.73569619634 0.616731335954\n",
      "calculation so far took 44.47417378425598  seconds\n",
      "step  129 of  1000\n",
      "1.73569619634 0.754215324967\n",
      "calculation so far took 44.785083055496216  seconds\n",
      "step  130 of  1000\n",
      "1.73569619634 0.79449702055\n",
      "calculation so far took 45.13628816604614  seconds\n",
      "step  131 of  1000\n",
      "1.73569619634 0.67337959324\n",
      "calculation so far took 45.470685720443726  seconds\n",
      "step  132 of  1000\n",
      "1.73569619634 0.602736447293\n",
      "calculation so far took 45.81860661506653  seconds\n",
      "step  133 of  1000\n",
      "1.73569619634 0.87610252235\n",
      "calculation so far took 46.155821323394775  seconds\n",
      "step  134 of  1000\n",
      "1.73569619634 1.0246729979\n",
      "calculation so far took 46.48316717147827  seconds\n",
      "step  135 of  1000\n",
      "1.73569619634 1.24805550287\n",
      "calculation so far took 46.81196975708008  seconds\n",
      "step  136 of  1000\n",
      "1.73569619634 1.04465698938\n",
      "calculation so far took 47.159956216812134  seconds\n",
      "step  137 of  1000\n",
      "1.73569619634 1.19433154776\n",
      "calculation so far took 47.50167107582092  seconds\n",
      "step  138 of  1000\n",
      "1.73569619634 0.932738858234\n",
      "calculation so far took 47.85813117027283  seconds\n",
      "step  139 of  1000\n",
      "1.73569619634 0.778799614245\n",
      "calculation so far took 48.20466351509094  seconds\n",
      "step  140 of  1000\n",
      "1.73569619634 0.688842218322\n",
      "calculation so far took 48.54259443283081  seconds\n",
      "step  141 of  1000\n",
      "1.73569619634 0.802686762341\n",
      "calculation so far took 48.92131471633911  seconds\n",
      "step  142 of  1000\n",
      "1.73569619634 0.889397621128\n",
      "calculation so far took 49.29177236557007  seconds\n",
      "step  143 of  1000\n",
      "1.73569619634 0.919053754822\n",
      "calculation so far took 49.65028977394104  seconds\n",
      "step  144 of  1000\n",
      "1.73569619634 0.903303009154\n",
      "calculation so far took 49.99633598327637  seconds\n",
      "step  145 of  1000\n",
      "1.73569619634 0.853975219828\n",
      "calculation so far took 50.34117555618286  seconds\n",
      "step  146 of  1000\n",
      "1.73569619634 0.841657147509\n",
      "calculation so far took 50.68714356422424  seconds\n",
      "step  147 of  1000\n",
      "1.73569619634 0.684543583699\n",
      "calculation so far took 51.03565764427185  seconds\n",
      "step  148 of  1000\n",
      "1.73569619634 0.537319626232\n",
      "calculation so far took 51.358354330062866  seconds\n",
      "step  149 of  1000\n",
      "1.73569619634 0.469772874942\n",
      "calculation so far took 51.67872738838196  seconds\n",
      "step  150 of  1000\n",
      "1.73569619634 0.737972519848\n",
      "calculation so far took 52.00923752784729  seconds\n",
      "step  151 of  1000\n",
      "1.73569619634 0.853060988899\n",
      "calculation so far took 52.34825348854065  seconds\n",
      "step  152 of  1000\n",
      "1.73569619634 0.993402866332\n",
      "calculation so far took 52.66207265853882  seconds\n",
      "step  153 of  1000\n",
      "1.73569619634 0.809493197845\n",
      "calculation so far took 52.977131605148315  seconds\n",
      "step  154 of  1000\n",
      "1.73569619634 0.812009644911\n",
      "calculation so far took 53.30797576904297  seconds\n",
      "step  155 of  1000\n",
      "1.73569619634 0.774912163078\n",
      "calculation so far took 53.629018783569336  seconds\n",
      "step  156 of  1000\n",
      "1.73569619634 0.68684963633\n",
      "calculation so far took 53.95274496078491  seconds\n",
      "step  157 of  1000\n",
      "1.73569619634 0.810879706044\n",
      "calculation so far took 54.288973569869995  seconds\n",
      "step  158 of  1000\n",
      "1.73569619634 0.894443219051\n",
      "calculation so far took 54.665292739868164  seconds\n",
      "step  159 of  1000\n",
      "1.73569619634 1.08969952058\n",
      "calculation so far took 55.0120267868042  seconds\n",
      "step  160 of  1000\n",
      "1.73569619634 0.969532309698\n",
      "calculation so far took 55.35385274887085  seconds\n",
      "step  161 of  1000\n",
      "1.73569619634 0.981697865746\n",
      "calculation so far took 55.69334697723389  seconds\n",
      "step  162 of  1000\n",
      "1.73569619634 0.622873528149\n",
      "calculation so far took 56.03001117706299  seconds\n",
      "step  163 of  1000\n",
      "1.73569619634 0.910820078423\n",
      "calculation so far took 56.38547348976135  seconds\n",
      "step  164 of  1000\n",
      "1.73569619634 1.02242021949\n",
      "calculation so far took 56.73423194885254  seconds\n",
      "step  165 of  1000\n",
      "1.73569619634 1.07629314366\n",
      "calculation so far took 57.10116982460022  seconds\n",
      "step  166 of  1000\n",
      "1.73569619634 0.95176730503\n",
      "calculation so far took 57.424134492874146  seconds\n",
      "step  167 of  1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.73569619634 0.892286368603\n",
      "calculation so far took 57.78285574913025  seconds\n",
      "step  168 of  1000\n",
      "1.73569619634 0.819012153616\n",
      "calculation so far took 58.12380337715149  seconds\n",
      "step  169 of  1000\n",
      "1.73569619634 0.755968735473\n",
      "calculation so far took 58.46123647689819  seconds\n",
      "step  170 of  1000\n",
      "1.73569619634 0.742560263055\n",
      "calculation so far took 58.78768181800842  seconds\n",
      "step  171 of  1000\n",
      "1.73569619634 0.94297425987\n",
      "calculation so far took 59.149317264556885  seconds\n",
      "step  172 of  1000\n",
      "1.73569619634 1.23469731234\n",
      "calculation so far took 59.49305820465088  seconds\n",
      "step  173 of  1000\n",
      "1.73569619634 1.09166600779\n",
      "calculation so far took 59.83216738700867  seconds\n",
      "step  174 of  1000\n",
      "1.73569619634 0.892427442737\n",
      "calculation so far took 60.181599617004395  seconds\n",
      "step  175 of  1000\n",
      "1.73569619634 0.813513183578\n",
      "calculation so far took 60.51658749580383  seconds\n",
      "step  176 of  1000\n",
      "1.73569619634 0.637795377184\n",
      "calculation so far took 60.84281611442566  seconds\n",
      "step  177 of  1000\n",
      "1.73569619634 0.766004742544\n",
      "calculation so far took 61.17293667793274  seconds\n",
      "step  178 of  1000\n",
      "1.73569619634 0.641071393968\n",
      "calculation so far took 61.510393381118774  seconds\n",
      "step  179 of  1000\n",
      "1.73569619634 0.785242795295\n",
      "calculation so far took 61.8369357585907  seconds\n",
      "step  180 of  1000\n",
      "1.73569619634 0.892361916317\n",
      "calculation so far took 62.171918869018555  seconds\n",
      "step  181 of  1000\n",
      "1.73569619634 0.93126954374\n",
      "calculation so far took 62.48608756065369  seconds\n",
      "step  182 of  1000\n",
      "1.73569619634 1.03132705303\n",
      "calculation so far took 62.80715823173523  seconds\n",
      "step  183 of  1000\n",
      "1.73569619634 1.03844957916\n",
      "calculation so far took 63.155731201171875  seconds\n",
      "step  184 of  1000\n",
      "1.73569619634 1.08699294764\n",
      "calculation so far took 63.48136639595032  seconds\n",
      "step  185 of  1000\n",
      "1.73569619634 1.2001222561\n",
      "calculation so far took 63.82947492599487  seconds\n",
      "step  186 of  1000\n",
      "1.73569619634 1.2453438369\n",
      "calculation so far took 64.18122577667236  seconds\n",
      "step  187 of  1000\n",
      "1.73569619634 1.05576202528\n",
      "calculation so far took 64.50081300735474  seconds\n",
      "step  188 of  1000\n",
      "1.73569619634 1.14650548899\n",
      "calculation so far took 64.816091299057  seconds\n",
      "step  189 of  1000\n",
      "1.73569619634 1.04226571203\n",
      "calculation so far took 65.14362049102783  seconds\n",
      "step  190 of  1000\n",
      "1.73569619634 1.16071089267\n",
      "calculation so far took 65.46477842330933  seconds\n",
      "step  191 of  1000\n",
      "1.73569619634 1.15983688163\n",
      "calculation so far took 65.77966690063477  seconds\n",
      "step  192 of  1000\n",
      "1.73569619634 1.20005821447\n",
      "calculation so far took 66.0969169139862  seconds\n",
      "step  193 of  1000\n",
      "1.73569619634 0.92873235495\n",
      "calculation so far took 66.4110701084137  seconds\n",
      "step  194 of  1000\n",
      "1.73569619634 0.728055900392\n",
      "calculation so far took 66.73548579216003  seconds\n",
      "step  195 of  1000\n",
      "1.73569619634 0.776309227019\n",
      "calculation so far took 67.05471396446228  seconds\n",
      "step  196 of  1000\n",
      "1.73569619634 1.01026257391\n",
      "calculation so far took 67.37588119506836  seconds\n",
      "step  197 of  1000\n",
      "1.73569619634 1.00268856344\n",
      "calculation so far took 67.68570232391357  seconds\n",
      "step  198 of  1000\n",
      "1.73569619634 1.21834545438\n",
      "calculation so far took 68.00558114051819  seconds\n",
      "step  199 of  1000\n",
      "1.73569619634 1.29857091799\n",
      "calculation so far took 68.3190381526947  seconds\n",
      "step  200 of  1000\n",
      "1.73569619634 1.15365436321\n",
      "calculation so far took 68.63711857795715  seconds\n",
      "step  201 of  1000\n",
      "1.73569619634 1.22491794229\n",
      "calculation so far took 68.94031047821045  seconds\n",
      "step  202 of  1000\n",
      "1.73569619634 1.03861985515\n",
      "calculation so far took 69.25429105758667  seconds\n",
      "step  203 of  1000\n",
      "1.73569619634 1.10525745048\n",
      "calculation so far took 69.57242393493652  seconds\n",
      "step  204 of  1000\n",
      "1.73569619634 1.11369763124\n",
      "calculation so far took 69.8883216381073  seconds\n",
      "step  205 of  1000\n",
      "1.73569619634 0.931889414427\n",
      "calculation so far took 70.20138335227966  seconds\n",
      "step  206 of  1000\n",
      "1.73569619634 0.845113455446\n",
      "calculation so far took 70.51507568359375  seconds\n",
      "step  207 of  1000\n",
      "1.73569619634 0.936372077244\n",
      "calculation so far took 70.81936955451965  seconds\n",
      "step  208 of  1000\n",
      "1.73569619634 0.9834990964\n",
      "calculation so far took 71.13717818260193  seconds\n",
      "step  209 of  1000\n",
      "1.73569619634 0.916424873887\n",
      "calculation so far took 71.45019483566284  seconds\n",
      "step  210 of  1000\n",
      "1.73569619634 0.905816504821\n",
      "calculation so far took 71.77118158340454  seconds\n",
      "step  211 of  1000\n",
      "1.73569619634 1.10682585279\n",
      "calculation so far took 72.0840790271759  seconds\n",
      "step  212 of  1000\n",
      "1.73569619634 1.250365769\n",
      "calculation so far took 72.40980505943298  seconds\n",
      "step  213 of  1000\n",
      "1.73569619634 1.26323650215\n",
      "calculation so far took 72.72710609436035  seconds\n",
      "step  214 of  1000\n",
      "1.73569619634 1.02863662752\n",
      "calculation so far took 73.03820657730103  seconds\n",
      "step  215 of  1000\n",
      "1.73569619634 0.799456151081\n",
      "calculation so far took 73.35595536231995  seconds\n",
      "step  216 of  1000\n",
      "1.73569619634 0.79857850473\n",
      "calculation so far took 73.68721437454224  seconds\n",
      "step  217 of  1000\n",
      "1.73569619634 0.776898322477\n",
      "calculation so far took 74.00346207618713  seconds\n",
      "step  218 of  1000\n",
      "1.73569619634 0.76200748936\n",
      "calculation so far took 74.33050560951233  seconds\n",
      "step  219 of  1000\n",
      "1.73569619634 1.02038692349\n",
      "calculation so far took 74.65543150901794  seconds\n",
      "step  220 of  1000\n",
      "1.73569619634 0.81859006396\n",
      "calculation so far took 74.97027230262756  seconds\n",
      "step  221 of  1000\n",
      "1.73569619634 0.884671953616\n",
      "calculation so far took 75.28586626052856  seconds\n",
      "step  222 of  1000\n",
      "1.73569619634 0.896365113995\n",
      "calculation so far took 75.60072088241577  seconds\n",
      "step  223 of  1000\n",
      "1.73569619634 0.834917519101\n",
      "calculation so far took 75.91304802894592  seconds\n",
      "step  224 of  1000\n",
      "1.73569619634 1.02416487929\n",
      "calculation so far took 76.23054766654968  seconds\n",
      "step  225 of  1000\n",
      "1.73569619634 1.34241099943\n",
      "calculation so far took 76.54537153244019  seconds\n",
      "step  226 of  1000\n",
      "1.73569619634 1.47669197846\n",
      "calculation so far took 76.85890674591064  seconds\n",
      "step  227 of  1000\n",
      "1.73569619634 1.3587118498\n",
      "calculation so far took 77.17586946487427  seconds\n",
      "step  228 of  1000\n",
      "1.73569619634 1.22904214514\n",
      "calculation so far took 77.49799180030823  seconds\n",
      "step  229 of  1000\n",
      "1.73569619634 1.40020902511\n",
      "calculation so far took 77.8132221698761  seconds\n",
      "step  230 of  1000\n",
      "1.73569619634 1.24982967644\n",
      "calculation so far took 78.12993168830872  seconds\n",
      "step  231 of  1000\n",
      "1.73569619634 1.22790091015\n",
      "calculation so far took 78.44466137886047  seconds\n",
      "step  232 of  1000\n",
      "1.73569619634 1.16699390371\n",
      "calculation so far took 78.75609159469604  seconds\n",
      "step  233 of  1000\n",
      "1.73569619634 1.06605538203\n",
      "calculation so far took 79.07113766670227  seconds\n",
      "step  234 of  1000\n",
      "1.73569619634 1.11182864467\n",
      "calculation so far took 79.38812375068665  seconds\n",
      "step  235 of  1000\n",
      "1.73569619634 1.18658478723\n",
      "calculation so far took 79.7073884010315  seconds\n",
      "step  236 of  1000\n",
      "1.73569619634 1.06289053657\n",
      "calculation so far took 80.02393817901611  seconds\n",
      "step  237 of  1000\n",
      "1.73569619634 0.948215103324\n",
      "calculation so far took 80.34147453308105  seconds\n",
      "step  238 of  1000\n",
      "1.73569619634 1.03795081276\n",
      "calculation so far took 80.6557469367981  seconds\n",
      "step  239 of  1000\n",
      "1.73569619634 1.37123665542\n",
      "calculation so far took 80.97136378288269  seconds\n",
      "step  240 of  1000\n",
      "1.73569619634 1.08601374182\n",
      "calculation so far took 81.2883927822113  seconds\n",
      "step  241 of  1000\n",
      "1.73569619634 1.19075008039\n",
      "calculation so far took 81.60948777198792  seconds\n",
      "step  242 of  1000\n",
      "1.73569619634 1.16378699092\n",
      "calculation so far took 81.92949199676514  seconds\n",
      "step  243 of  1000\n",
      "1.73569619634 1.14875666975\n",
      "calculation so far took 82.2468752861023  seconds\n",
      "step  244 of  1000\n",
      "1.73569619634 0.989858211474\n",
      "calculation so far took 82.56943607330322  seconds\n",
      "step  245 of  1000\n",
      "1.73569619634 0.872040887872\n",
      "calculation so far took 82.88529539108276  seconds\n",
      "step  246 of  1000\n",
      "1.73569619634 0.983511981913\n",
      "calculation so far took 83.19845366477966  seconds\n",
      "step  247 of  1000\n",
      "1.73569619634 0.812694167313\n",
      "calculation so far took 83.51487326622009  seconds\n",
      "step  248 of  1000\n",
      "1.73569619634 0.743229524225\n",
      "calculation so far took 83.82847166061401  seconds\n",
      "step  249 of  1000\n",
      "1.73569619634 0.911939904863\n",
      "calculation so far took 84.14524602890015  seconds\n",
      "step  250 of  1000\n",
      "1.73569619634 1.04146274943\n",
      "calculation so far took 84.4695930480957  seconds\n",
      "step  251 of  1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.73569619634 1.00829058801\n",
      "calculation so far took 84.81325054168701  seconds\n",
      "step  252 of  1000\n",
      "1.73569619634 0.934569381939\n",
      "calculation so far took 85.14925003051758  seconds\n",
      "step  253 of  1000\n",
      "1.73569619634 1.0997155267\n",
      "calculation so far took 85.48931050300598  seconds\n",
      "step  254 of  1000\n",
      "1.73569619634 0.913683235668\n",
      "calculation so far took 85.80446076393127  seconds\n",
      "step  255 of  1000\n",
      "1.73569619634 1.01269284634\n",
      "calculation so far took 86.13122391700745  seconds\n",
      "step  256 of  1000\n",
      "1.73569619634 1.13767169983\n",
      "calculation so far took 86.44597792625427  seconds\n",
      "step  257 of  1000\n",
      "1.73569619634 1.27026217753\n",
      "calculation so far took 86.7755115032196  seconds\n",
      "step  258 of  1000\n",
      "1.73569619634 1.29070244067\n",
      "calculation so far took 87.09938406944275  seconds\n",
      "step  259 of  1000\n",
      "1.73569619634 1.04131671026\n",
      "calculation so far took 87.46312880516052  seconds\n",
      "step  260 of  1000\n",
      "1.73569619634 1.06860324964\n",
      "calculation so far took 87.83285307884216  seconds\n",
      "step  261 of  1000\n",
      "1.73569619634 1.21718274769\n",
      "calculation so far took 88.22072267532349  seconds\n",
      "step  262 of  1000\n",
      "1.73569619634 1.05772220025\n",
      "calculation so far took 88.57013273239136  seconds\n",
      "step  263 of  1000\n",
      "1.73569619634 1.01605455889\n",
      "calculation so far took 88.89136838912964  seconds\n",
      "step  264 of  1000\n",
      "1.73569619634 1.0451596815\n",
      "calculation so far took 89.20823812484741  seconds\n",
      "step  265 of  1000\n",
      "1.73569619634 1.23872535061\n",
      "calculation so far took 89.54336357116699  seconds\n",
      "step  266 of  1000\n",
      "1.73569619634 1.14933470394\n",
      "calculation so far took 89.9182276725769  seconds\n",
      "step  267 of  1000\n",
      "1.73569619634 1.09498511775\n",
      "calculation so far took 90.2998378276825  seconds\n",
      "step  268 of  1000\n",
      "1.73569619634 0.928129538249\n",
      "calculation so far took 90.63385343551636  seconds\n",
      "step  269 of  1000\n",
      "1.73569619634 0.991616577812\n",
      "calculation so far took 90.97776079177856  seconds\n",
      "step  270 of  1000\n",
      "1.73569619634 0.810177654157\n",
      "calculation so far took 91.31408667564392  seconds\n",
      "step  271 of  1000\n",
      "1.73569619634 1.07916965768\n",
      "calculation so far took 91.64238286018372  seconds\n",
      "step  272 of  1000\n",
      "1.73569619634 1.0204619858\n",
      "calculation so far took 91.96403336524963  seconds\n",
      "step  273 of  1000\n",
      "1.73569619634 1.03565957283\n",
      "calculation so far took 92.29754376411438  seconds\n",
      "step  274 of  1000\n",
      "1.73569619634 1.08932246626\n",
      "calculation so far took 92.62533831596375  seconds\n",
      "step  275 of  1000\n",
      "1.73569619634 0.968406170068\n",
      "calculation so far took 92.96532106399536  seconds\n",
      "step  276 of  1000\n",
      "1.73569619634 0.898807054675\n",
      "calculation so far took 93.29441261291504  seconds\n",
      "step  277 of  1000\n",
      "1.73569619634 0.845743129975\n",
      "calculation so far took 93.60937356948853  seconds\n",
      "step  278 of  1000\n",
      "1.73569619634 0.987106115505\n",
      "calculation so far took 93.94609761238098  seconds\n",
      "step  279 of  1000\n",
      "1.73569619634 1.06394071921\n",
      "calculation so far took 94.27631378173828  seconds\n",
      "step  280 of  1000\n",
      "1.73569619634 1.12455678343\n",
      "calculation so far took 94.61903476715088  seconds\n",
      "step  281 of  1000\n",
      "1.73569619634 1.27758004759\n",
      "calculation so far took 94.93388843536377  seconds\n",
      "step  282 of  1000\n",
      "1.73569619634 1.29041403171\n",
      "calculation so far took 95.25461268424988  seconds\n",
      "step  283 of  1000\n",
      "1.73569619634 1.31168604852\n",
      "calculation so far took 95.57848834991455  seconds\n",
      "step  284 of  1000\n",
      "1.73569619634 1.29811350046\n",
      "calculation so far took 95.90625476837158  seconds\n",
      "step  285 of  1000\n",
      "1.73569619634 1.30172281719\n",
      "calculation so far took 96.22733449935913  seconds\n",
      "step  286 of  1000\n",
      "1.73569619634 1.19316208196\n",
      "calculation so far took 96.56648111343384  seconds\n",
      "step  287 of  1000\n",
      "1.73569619634 1.10144834829\n",
      "calculation so far took 96.92720246315002  seconds\n",
      "step  288 of  1000\n",
      "1.73569619634 1.22457413002\n",
      "calculation so far took 97.28432536125183  seconds\n",
      "step  289 of  1000\n",
      "1.73569619634 1.16810195533\n",
      "calculation so far took 97.64311599731445  seconds\n",
      "step  290 of  1000\n",
      "1.73569619634 1.19755369744\n",
      "calculation so far took 98.0184109210968  seconds\n",
      "step  291 of  1000\n",
      "1.73569619634 1.3899470587\n",
      "calculation so far took 98.3811252117157  seconds\n",
      "step  292 of  1000\n",
      "1.73569619634 1.29257909376\n",
      "calculation so far took 98.73822593688965  seconds\n",
      "step  293 of  1000\n",
      "1.73569619634 1.33661731905\n",
      "calculation so far took 99.12009048461914  seconds\n",
      "step  294 of  1000\n",
      "1.73569619634 1.32683171867\n",
      "calculation so far took 99.47411680221558  seconds\n",
      "step  295 of  1000\n",
      "1.73569619634 1.06574456656\n",
      "calculation so far took 99.82730865478516  seconds\n",
      "step  296 of  1000\n",
      "1.73569619634 1.23693601874\n",
      "calculation so far took 100.2020902633667  seconds\n",
      "step  297 of  1000\n",
      "1.73569619634 1.27678769075\n",
      "calculation so far took 100.5412209033966  seconds\n",
      "step  298 of  1000\n",
      "1.73569619634 1.14295777229\n",
      "calculation so far took 100.9359495639801  seconds\n",
      "step  299 of  1000\n",
      "1.73569619634 1.10788469197\n",
      "calculation so far took 101.2833743095398  seconds\n",
      "step  300 of  1000\n",
      "1.73569619634 1.26332445141\n",
      "calculation so far took 101.61379289627075  seconds\n",
      "step  301 of  1000\n",
      "1.73569619634 1.15589860383\n",
      "calculation so far took 101.97067022323608  seconds\n",
      "step  302 of  1000\n",
      "1.73569619634 1.20555500044\n",
      "calculation so far took 102.29338240623474  seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([-2.22414284, -3.34377459, -0.28479125,  0.51975264,  0.45931538]),\n",
       " 'initial minimization']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a wrapper for MCMC (with initial global optimisation to speed up convergence)\n",
    "from Chempy.wrapper import single_star_optimization\n",
    "single_star_optimization() # NB: if not using a neural network, multi_star_optimization() should be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Chempy.plot_mcmc import restructure_chain,plot_mcmc_chain_with_prior\n",
    "restructure_chain('mcmc/') # Restructure the MCMC chain\n",
    "\n",
    "# Compute best parameter values\n",
    "\n",
    "\n",
    "START HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now create the corner plot (saved as mcmc/parameter_space_sorted.png)\n",
    "plot_mcmc_chain_with_prior('BestMCMC/',use_prior=True,only_first_star=False,plot_true_parameters=False,plot_only_SSP_parameter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Bayes + LOO-CV Scores as a function of $\\beta$\n",
    "\n",
    "We are now ready to compute both the Bayes and LOO-CV scores for the network. Before computation, we instruct *Chempy* to use the trained neural network which is done by altering the `Chempy/parameter.py` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Modify these lines in Chempy/parameter.py\n",
    "UseNeural = True \n",
    "\n",
    "# To test if this has worked:\n",
    "a.UseNeural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Compute Overall Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
