{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test datasets for 1,2,3,4,5 sigma widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from Chempy.parameter import ModelParameters\n",
    "from Chempy.cem_function import posterior_function_returning_predictions\n",
    "\n",
    "def test_dataset(width,size):\n",
    "    \"\"\"\n",
    "    Create test dataset for fixed gaussian width.\n",
    "    The data points are randomly distributed along a uniform distribution with fixed width in parameter space.\n",
    "    \n",
    "    Input: width of test dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    a = ModelParameters()\n",
    "    \n",
    "    lower = np.zeros(len(a.p0))\n",
    "    upper = np.zeros(len(a.p0))\n",
    "\n",
    "    # Set upper/lower bounds in parameter space\n",
    "    for i,param_name in enumerate(a.to_optimize):\n",
    "        lower[i], upper[i] = a.constraints.get(param_name)\n",
    "        \n",
    "    sigma = []\n",
    "    for i,param_name in enumerate(a.to_optimize):\n",
    "        sigma.append(a.priors.get(param_name)[1])\n",
    "\n",
    "    param_grid = []\n",
    "    abundance_grid = []\n",
    "    for i in range(size):\n",
    "        if i%10==0:\n",
    "            print('Calculating sample %d of %d' %(i+1,size))\n",
    "        param = np.random.uniform(a.p0-width*np.array(sigma),a.p0+width*np.array(sigma))\n",
    "        pred,_ = posterior_function_returning_predictions((param,a))\n",
    "        param_grid.append(list(param))\n",
    "        abundance_grid.append(list(pred))\n",
    "       \n",
    "    np.save('SingleElement/'+str(width)+'_sigma_param_grid.npy',param_grid)\n",
    "    np.save('SingleElement/'+str(width)+'_sigma_abundances.npy',abundance_grid)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating sample 1 of 3\n"
     ]
    }
   ],
   "source": [
    "test_dataset(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def verification_and_testing():\n",
    "\t\"\"\" This will create the verification and testing data-sets for use with the neural network.\n",
    "\tThe data-sets are created randomly from the Gaussian prior distribution, within the bounds set in the parameter file\n",
    "\n",
    "\tOutputs (saved as .npy files in the Neural/ folder):\n",
    "\t\tverif_param_grid - Verification parameter data\n",
    "\t\tverif_abundances - Verification dataset abundances\n",
    "\t\ttest_param_grid - Test parameter data\n",
    "\t\ttest_abundances - Test dataset abundances\n",
    "\n",
    "\t\"\"\"\n",
    "\n",
    "\t# FOR TESTING\n",
    "\timport warnings\n",
    "\twarnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\ta = ModelParameters()\n",
    "\tnames = ['verif','test'] # Two datasets\n",
    "\n",
    "\tlower = np.zeros(len(a.p0))\n",
    "\tupper = np.zeros(len(a.p0))\n",
    "\n",
    "\t# Set upper/lower bounds in parameter space\n",
    "\tfor i,param_name in enumerate(a.to_optimize):\n",
    "\t\tlower[i], upper[i] = a.constraints.get(param_name)\n",
    "\n",
    "\tfor j ,name in enumerate(names): # Create both test sets\n",
    "\t\tparam_grid = []\n",
    "\t\tmodel_abundances = []\n",
    "\t\tfor k in range(a.verif_test_sizes[j]):\n",
    "\t\t\tparam = np.ones(len(a.p0))*np.inf # To ensure initial value is not in range\n",
    "\t\t\tfor i in range(len(a.p0)):\n",
    "\t\t\t\tparam[i] = np.inf\n",
    "\t\t\t\twhile param[i] > upper[i] or param[i] < lower[i]: # Continue until param is in correct range\n",
    "\t\t\t\t\tparam[i] = np.random.normal(loc=a.p0[i],scale=a.test_widths[i])\n",
    "\t\t\tparam_grid.append(param)\n",
    "\t\t\tabundances,_ = posterior_function_returning_predictions((param,a))\n",
    "\t\t\tmodel_abundances.append(abundances)\n",
    "\t\t\tif k%100==0 :\n",
    "\t\t\t\tprint(\"Calculating %s abundance set %d of %d\" %(name,k,a.verif_test_sizes[j]))\n",
    "\t\tnp.save(\"Neural/\"+name+\"_param_grid.npy\",param_grid)\n",
    "\t\tnp.save(\"Neural/\"+name+\"_abundances.npy\",model_abundances)\n",
    "\n",
    "\treturn None\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
