{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sample grid for training data (code in neural.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Chempy.parameter import ModelParameters\n",
    "from Chempy.cem_function import posterior_function_returning_predictions\n",
    "from scipy.stats import norm as gaussian\n",
    "import os\n",
    "a = ModelParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This calculates a list of 5 trial values for each parameter around the prior value, as an array of 6 lists which will be combined\n",
    "# Set the desired Gaussian sigma values in the widths parameter (values > prior sigma are used to fully explore parameter space)\n",
    "# Parameter values are chosen that are evenly distributed in the Gaussian probability space (e.g. 16.7, 33, 50 etc. percentile points)\n",
    "\n",
    "N = a.training_size # No. data points per parameter\n",
    "widths = a.training_widths # Gaussian widths for parameters\n",
    "\n",
    "# Create 1d grid of data points equally spaced in probability space \n",
    "prob = np.linspace(1/(N+1), 1-1/(N+1), N)\n",
    "grids = [gaussian.ppf(prob) for _ in range(N+1)] # Normalize to unit Gaussian\n",
    "norm_grid = np.array(np.meshgrid(*grids)).T.reshape(-1,N+1)\n",
    "\n",
    "# Create grid in parameter space\n",
    "param_grid = [item*widths+a.p0 for item in norm_grid]\n",
    "\n",
    "# Save grids\n",
    "directory = 'Neural/'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "np.save(directory+'training_norm_grid.npy',norm_grid)\n",
    "np.save(directory+'training_param_grid.npy',param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create abundance output\n",
    "param_grid = param_grid[:10] # For testing\n",
    "training_abundances = []\n",
    "for i,item in enumerate(param_grid):\n",
    "    abundances,_ = posterior_function_returning_predictions((item,a))\n",
    "    training_abundances.append(abundances)\n",
    "    if i%100 == 0:\n",
    "        print(\"Calculating abundance set %d of %d\" %(i,len(param_grid)))\n",
    "              \n",
    "# Save abundance table\n",
    "np.save('Neural/training_abundances.npy', training_abundances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES\n",
    "\n",
    "- All code is now in neural.py file\n",
    "- Should put changeable parameters e.g. number of choices for each parameter in parameter.py file - DONE\n",
    "-  Find nicer way of using all rows from grid - DONE\n",
    "- Check whether to use Karakas 10 or Karakas 16 - Karakas 10 for testing\n",
    "- Automate number of traceable elements - just copy that from code - DONE\n",
    "\n",
    "*This may be a useful reference https://arxiv.org/abs/1502.01852, for recommendation of ReLU units, with w = np.random.randn(n) x np.sqrt(2/n) for initialized weights, from Stanford course*\n",
    "\n",
    "*Another useful reference: https://arxiv.org/abs/1412.6980 for 'Adam' learning method viz Stanford course*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Verification / Testing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ModelParameters()\n",
    "names = ['verif','test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,name in enumerate(names): # Create two identically distributed datasets\n",
    "    length = a.verif_test_sizes[i]\n",
    "    param_grid = []\n",
    "    # Distribute data with prior widths\n",
    "    for _ in range(length):\n",
    "        param_grid.append(np.random.normal(size = len(a.p0), loc = a.p0,\n",
    "                                           scale = a.test_widths))\n",
    "    np.save(\"Neural/\"+name+\"_param_grid.npy\",param_grid)\n",
    "    \n",
    "    model_abundances = []\n",
    "    for j,jtem in enumerate(param_grid):\n",
    "        abundances,_ = posterior_function_returning_predictions((jtem,a))\n",
    "        model_abundances.append(abundances)\n",
    "        if j%100 == 0:\n",
    "            print(\"Calculating %s abundance set %d of %d\" %(name,j,length))\n",
    "            \n",
    "    # Save abundance table\n",
    "    np.save(\"Neural/\"+name+\"_abundances.npy\",model_abundances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,name in enumerate(names): # Create two identically distributed datasets\n",
    "    length = a.verif_test_sizes[i]\n",
    "    norm_grid = []\n",
    "    # Distribute data with prior width, but normalized with trial_widths as before\n",
    "    for _ in range(length):\n",
    "        norm_grid.append(np.random.normal(size = len(a.p0),\n",
    "                                          scale = np.array(a.test_widths)/np.array(a.training_widths)))\n",
    "     \n",
    "    # Convert data into normalized form\n",
    "    np.save(\"Neural/\"+name+\"_norm_grid.npy\",norm_grid)\n",
    "    \n",
    "    # Find the actual abundance grid\n",
    "    param_grid = [item*a.training_widths+a.p0 for item in norm_grid]\n",
    "    np.save(\"Neural/\"+name+\"_param_grid.npy\",param_grid)\n",
    "    \n",
    "    model_abundances = []\n",
    "    for j,jtem in enumerate(param_grid[:10]):\n",
    "        abundances,_ = posterior_function_returning_predictions((jtem,a))\n",
    "        model_abundances.append(abundances)\n",
    "        if j%2 == 0:\n",
    "            print(\"Calculating %s abundance set %d of %d\" %(name,j,length))\n",
    "            \n",
    "    # Save abundance table\n",
    "    np.save(\"Neural/\"+name+\"_abundances.npy\",model_abundances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import torch # Import PyTorch\n",
    "from torch.autograd import Variable\n",
    "from Chempy.parameter import ModelParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ModelParameters()\n",
    "\n",
    "n_train = a.training_size**len(a.p0) # Training data points\n",
    "n_neurons = a.neurons # No. neurons in layers\n",
    "\n",
    "# Load pre-processed training data\n",
    "tr_input = np.load('Neural/training_norm_grid.npy')\n",
    "tr_output = np.load('Neural/training_abundances.npy')\n",
    "\n",
    "# Calculate input dimension\n",
    "dim_in = tr_input.shape[1]\n",
    "dim_out = tr_output.shape[1]\n",
    "\n",
    "# Convert to torch variables\n",
    "tr_input = Variable(torch.from_numpy(tr_input)).type(torch.FloatTensor)\n",
    "tr_output = Variable(torch.from_numpy(tr_output), requires_grad=False).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate neural network - use one hidden layer and no. neurons specified in parameter.py.\n",
    "# CHANGE these hyperparameters if needed\n",
    "\n",
    "# Remove the below ##############\n",
    "model = []\n",
    "a.learning_rate = 0.001 \n",
    "##############################\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(dim_in, a.neurons),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(a.neurons,dim_out)\n",
    ")\n",
    "loss_fn = torch.nn.L1Loss(size_average=True)\n",
    "\n",
    "# Use Adam optimizer with specified learning rate in parameter.py\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = a.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convergence counter\n",
    "current_loss = 1000 # High inital loss set\n",
    "count = 0\n",
    "t = 0\n",
    "\n",
    "# Used for plotting loss\n",
    "losslog = []\n",
    "epoch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "# Train the neural netowrk\n",
    "for i in range(a.epochs): # PUT THIS IN PARAMETER.PY\n",
    "    pred_output = model(tr_input)\n",
    "    loss = loss_fn(pred_output,tr_output)\n",
    "    optimizer.zero_grad() # Zero gradients initially\n",
    "    loss.backward() # Backpropagate\n",
    "    optimizer.step() # Update via Adam method\n",
    "    \n",
    "   \n",
    "    # Print cost\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "        #print(loss.data[0])\n",
    "        losslog.append(loss.data[0])\n",
    "        epoch.append(i)\n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efce064f6d8>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nK4/w7h14dWwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efcec0b24a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch, losslog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to numpy arrays\n",
    "model_numpy = []\n",
    "for param in model.parameters():\n",
    "    model_numpy.append(param.data.numpy())\n",
    "    \n",
    "w_array_0 = model_numpy[0]\n",
    "b_array_0 = model_numpy[1]\n",
    "w_array_1 = model_numpy[2]\n",
    "b_array_1 = model_numpy[3]\n",
    "\n",
    "# Save parameters\n",
    "np.savez(\"Neural/neural_model.npz\",\n",
    "        w_array_0 = w_array_0,\n",
    "        w_array_1 = w_array_1,\n",
    "        b_array_0 = b_array_0,\n",
    "        b_array_1 = b_array_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_output(test_input):\n",
    "    \"\"\" This function will calculate the neural network predicted output.\n",
    "    The neural network must be trained first.\n",
    "    \n",
    "    Inputs: \n",
    "    test_input - Array containing unnormalized parameter values\n",
    "    neural_coeffs - Neural network weights, stored in neural_model.npz file\n",
    "    \n",
    "    Output: Neural network abundance prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load in most recent neural coefficients\n",
    "    neural_coeffs = np.load('Neural/neural_model.npz')\n",
    "    w_array_0 = neural_coeffs['w_array_0']\n",
    "    w_array_1 = neural_coeffs['w_array_1']\n",
    "    b_array_0 = neural_coeffs['b_array_0']\n",
    "    b_array_1 = neural_coeffs['b_array_1']\n",
    "    \n",
    "    activator = torch.nn.ReLU()\n",
    "    \n",
    "    # Normalize data for neural network input\n",
    "    norm_data = (test_input - a.p0)/np.array(a.training_widths)\n",
    "    \n",
    "    # Calculate neural network input\n",
    "    hidden = np.maximum(0,np.dot(w_array_0, norm_data) + b_array_0)\n",
    "    output = np.dot(w_array_1, hidden) + b_array_1\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate average error using 1000 epochs for Verification dataset\n",
    "verif_param = np.load('Neural/verif_param_grid.npy')\n",
    "verif_abundances = np.load('Neural/verif_abundances.npy')\n",
    "\n",
    "for i in range(a.verif_test_sizes[0]):\n",
    "    predicted_abundances = neural_output(verif_param[i])\n",
    "    # Compute L1 error between predicted and Chempy values\n",
    "    L1 = np.sum(np.mod)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just testing one value for now\n",
    "\n",
    "# Load verification dataset\n",
    "verif_param = np.load('Neural/verif_param_grid.npy')\n",
    "verif_abundances = np.load('Neural/verif_abundances.npy')\n",
    "\n",
    "prediction_out = neural_output(verif_param[24])\n",
    "model_out = verif_abundances[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the outputs\n",
    "\n",
    "%pylab inline \n",
    "# For testing\n",
    "\n",
    "x = np.arange(len(model_out))\n",
    "plt.plot(x,model_out,'r',label = 'Chempy')\n",
    "plt.plot(x,prediction_out,'b',label='Neural')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO**\n",
    "- Vary optimizer, ReLU function, L1Loss to see which gives best results\n",
    "- Which regularization method are we using??\n",
    "- Check initialized weights - sqrt(2/n) thing\n",
    "- Plot loss function against epoch\n",
    "- Plot accuracy on verification dataset against epoch\n",
    "- Vary learning_rate\n",
    "- Plot accuracy on test data as 2D coloured plot in parameter space for each pair\n",
    "\n",
    "**MUST change the predictions to output in NON normalized space**\n",
    "\n",
    "**NB: if change ReLU function, must change in update above AND output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
