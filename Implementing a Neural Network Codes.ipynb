{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sample grid for training data (code in neural.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Chempy.parameter import ModelParameters\n",
    "from Chempy.cem_function import posterior_function_returning_predictions\n",
    "from scipy.stats import norm as gaussian\n",
    "import os\n",
    "a = ModelParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This calculates a list of 5 trial values for each parameter around the prior value, as an array of 6 lists which will be combined\n",
    "# Set the desired Gaussian sigma values in the widths parameter (values > prior sigma are used to fully explore parameter space)\n",
    "# Parameter values are chosen that are evenly distributed in the Gaussian probability space (e.g. 16.7, 33, 50 etc. percentile points)\n",
    "\n",
    "N = a.training_size # No. data points per parameter\n",
    "widths = a.training_widths # Gaussian widths for parameters\n",
    "\n",
    "# Create 1d grid of data points equally spaced in probability space \n",
    "prob = np.linspace(1/(N+1), 1-1/(N+1), N)\n",
    "grids = [gaussian.ppf(prob) for _ in range(N+1)] # Normalize to unit Gaussian\n",
    "norm_grid = np.array(np.meshgrid(*grids)).T.reshape(-1,N+1)\n",
    "\n",
    "# Create grid in parameter space\n",
    "param_grid = [item*widths+a.p0 for item in norm_grid]\n",
    "\n",
    "# Save grids\n",
    "directory = 'Neural/'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "np.save(directory+'training_norm_grid.npy',norm_grid)\n",
    "np.save(directory+'training_param_grid.npy',param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create abundance output\n",
    "param_grid = param_grid[:10] # For testing\n",
    "training_abundances = []\n",
    "for i,item in enumerate(param_grid):\n",
    "    abundances,_ = posterior_function_returning_predictions((item,a))\n",
    "    training_abundances.append(abundances)\n",
    "    if i%100 == 0:\n",
    "        print(\"Calculating abundance set %d of %d\" %(i,len(param_grid)))\n",
    "              \n",
    "# Save abundance table\n",
    "np.save('Neural/training_abundances.npy', training_abundances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES\n",
    "\n",
    "- All code is now in neural.py file\n",
    "- Should put changeable parameters e.g. number of choices for each parameter in parameter.py file - DONE\n",
    "-  Find nicer way of using all rows from grid - DONE\n",
    "- Check whether to use Karakas 10 or Karakas 16 - Karakas 10 for testing\n",
    "- Automate number of traceable elements - just copy that from code - DONE\n",
    "\n",
    "*This may be a useful reference https://arxiv.org/abs/1502.01852, for recommendation of ReLU units, with w = np.random.randn(n) x np.sqrt(2/n) for initialized weights, from Stanford course*\n",
    "\n",
    "*Another useful reference: https://arxiv.org/abs/1412.6980 for 'Adam' learning method viz Stanford course*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Verification / Testing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ModelParameters()\n",
    "names = ['verif','test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating verif abundance set 0 of 1000\n",
      "gas reservoir is empty\n",
      "gas reservoir is empty\n",
      "gas reservoir is empty\n",
      "gas reservoir is empty\n",
      "gas reservoir is empty\n",
      "gas reservoir is empty\n",
      "gas reservoir is empty\n",
      "Calculating verif abundance set 2 of 1000\n",
      "Calculating verif abundance set 4 of 1000\n",
      "Calculating verif abundance set 6 of 1000\n",
      "Calculating verif abundance set 8 of 1000\n",
      "Calculating test abundance set 0 of 1000\n",
      "Calculating test abundance set 2 of 1000\n",
      "Calculating test abundance set 4 of 1000\n",
      "Calculating test abundance set 6 of 1000\n",
      "gas reservoir is empty\n",
      "gas reservoir is empty\n",
      "gas reservoir is empty\n",
      "gas reservoir is empty\n",
      "gas reservoir is empty\n",
      "gas reservoir is empty\n",
      "gas reservoir is empty\n",
      "gas reservoir is empty\n",
      "gas reservoir is empty\n",
      "gas reservoir is empty\n",
      "gas reservoir is empty\n",
      "gas reservoir is empty\n",
      "Calculating test abundance set 8 of 1000\n"
     ]
    }
   ],
   "source": [
    "for i,name in enumerate(names): # Create two identically distributed datasets\n",
    "    length = a.verif_test_sizes[i]\n",
    "    param_grid = []\n",
    "    # Distribute data with prior widths\n",
    "    for _ in range(length):\n",
    "        param_grid.append(np.random.normal(size = len(a.p0), loc = a.p0,\n",
    "                                           scale = a.test_widths))\n",
    "    np.save(\"Neural/\"+name+\"_param_grid.npy\",param_grid)\n",
    "    \n",
    "    model_abundances = []\n",
    "    for j,jtem in enumerate(param_grid):\n",
    "        abundances,_ = posterior_function_returning_predictions((jtem,a))\n",
    "        model_abundances.append(abundances)\n",
    "        if j%100 == 0:\n",
    "            print(\"Calculating %s abundance set %d of %d\" %(name,j,length))\n",
    "            \n",
    "    # Save abundance table\n",
    "    np.save(\"Neural/\"+name+\"_abundances.npy\",model_abundances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating verif abundance set 0 of 1000\n",
      "Calculating verif abundance set 2 of 1000\n",
      "Calculating verif abundance set 4 of 1000\n",
      "Calculating verif abundance set 6 of 1000\n",
      "Calculating verif abundance set 8 of 1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-68ec3232bc43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmodel_abundances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mjtem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mabundances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposterior_function_returning_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjtem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mmodel_abundances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabundances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philcox/Chempy/Chempy/cem_function.py\u001b[0m in \u001b[0;36mposterior_function_returning_predictions\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    462\u001b[0m \t'''\n\u001b[1;32m    463\u001b[0m         \u001b[0mchanging_parameter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0mposterior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabundance_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposterior_function_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchanging_parameter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mabundance_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0melement_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philcox/Chempy/Chempy/cem_function.py\u001b[0m in \u001b[0;36mposterior_function_predictions\u001b[0;34m(changing_parameter, a)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;31m# call Chempy and return the abundances at the end of the simulation = time of star's birth and the corresponding element names as a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0mabundance_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0melements_to_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcem_real2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m         \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_mass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philcox/Chempy/Chempy/cem_function.py\u001b[0m in \u001b[0;36mcem_real2\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;31m### Model is calculated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_model\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m                 \u001b[0mcube\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabundances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChempy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m                 \u001b[0mcube1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcube\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0mgas_reservoir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgas_reservoir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philcox/Chempy/Chempy/wrapper.py\u001b[0m in \u001b[0;36mChempy\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mtime_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_sfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mbasic_ssp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_feedback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetallicity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melements_to_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement_fractions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 \u001b[0mcube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance_one_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_ssp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_ssp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msn2_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_ssp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magb_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_ssp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msn1a_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcube\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasic_sfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philcox/Chempy/Chempy/time_integration.py\u001b[0m in \u001b[0;36madvance_one_step\u001b[0;34m(self, index, ssp_yield, sn2_yield, agb_yield, sn1a_yield)\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0;31m## gas reservoir gas is taken away and infalling on cube_gas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcube\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfall\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgas_reservoir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgas_reservoir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgas_reservoir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfall\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgas_reservoir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgas_reservoir\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philcox/anaconda3/lib/python3.6/site-packages/numpy/core/records.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, indx)\u001b[0m\n\u001b[1;32m    508\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;31m# return a single element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i,name in enumerate(names): # Create two identically distributed datasets\n",
    "    length = a.verif_test_sizes[i]\n",
    "    norm_grid = []\n",
    "    # Distribute data with prior width, but normalized with trial_widths as before\n",
    "    for _ in range(length):\n",
    "        norm_grid.append(np.random.normal(size = len(a.p0),\n",
    "                                          scale = np.array(a.test_widths)/np.array(a.training_widths)))\n",
    "     \n",
    "    # Convert data into normalized form\n",
    "    np.save(\"Neural/\"+name+\"_norm_grid.npy\",norm_grid)\n",
    "    \n",
    "    # Find the actual abundance grid\n",
    "    param_grid = [item*a.training_widths+a.p0 for item in norm_grid]\n",
    "    np.save(\"Neural/\"+name+\"_param_grid.npy\",param_grid)\n",
    "    \n",
    "    model_abundances = []\n",
    "    for j,jtem in enumerate(param_grid[:10]):\n",
    "        abundances,_ = posterior_function_returning_predictions((jtem,a))\n",
    "        model_abundances.append(abundances)\n",
    "        if j%2 == 0:\n",
    "            print(\"Calculating %s abundance set %d of %d\" %(name,j,length))\n",
    "            \n",
    "    # Save abundance table\n",
    "    np.save(\"Neural/\"+name+\"_abundances.npy\",model_abundances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import torch # Import PyTorch\n",
    "from torch.autograd import Variable\n",
    "from Chempy.parameter import ModelParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ModelParameters()\n",
    "\n",
    "n_train = a.training_size**len(a.p0) # Training data points\n",
    "n_neurons = a.neurons # No. neurons in layers\n",
    "\n",
    "# Load pre-processed training data\n",
    "tr_input = np.load('Neural/training_norm_grid.npy')\n",
    "tr_output = np.load('Neural/training_abundances.npy')\n",
    "\n",
    "# Calculate input dimension\n",
    "dim_in = tr_input.shape[1]\n",
    "dim_out = tr_output.shape[1]\n",
    "\n",
    "# Convert to torch variables\n",
    "tr_input = Variable(torch.from_numpy(tr_input)).type(torch.FloatTensor)\n",
    "tr_output = Variable(torch.from_numpy(tr_output), requires_grad=False).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate neural network - use one hidden layer and no. neurons specified in parameter.py.\n",
    "# CHANGE these hyperparameters if needed\n",
    "model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(dim_in, a.neurons),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(a.neurons,dim_out)\n",
    ")\n",
    "loss_fn = torch.nn.L1Loss(size_average=True)\n",
    "\n",
    "# Use Adam optimizer with specified learning rate in parameter.py\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = a.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convergence counter\n",
    "current_loss = 1000 # High inital loss set\n",
    "count = 0\n",
    "t = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the neural netowrk\n",
    "for i in range(int(1e2)):\n",
    "    pred_output = model(tr_input)\n",
    "    loss = loss_fn(pred_output,tr_output)\n",
    "    optimizer.zero_grad() # Zero gradients initially\n",
    "    loss.backward() # Backpropagate\n",
    "    optimizer.step() # Update via Adam method\n",
    "    \n",
    "    # Print cost\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "        print(loss.data[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert back to numpy\n",
    "model_numpy = []\n",
    "for param in model.parameters():\n",
    "    model_numpy.append(param.data.numpy())\n",
    "    \n",
    "w_array_0 = model_numpy[0]\n",
    "b_array_0 = model_numpy[1]\n",
    "w_array_1 = model_numpy[2]\n",
    "b_array_1 = model_numpy[3]\n",
    "\n",
    "# Save parameters\n",
    "np.savez(\"Numpy/neural_model.npz\",\n",
    "        w_array_0 = w_array_0,\n",
    "        w_array_1 = w_array_1,\n",
    "        b_array_0 = b_array_0,\n",
    "        b_array_1 = b_array_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neural_output(test_input,neural_coeffs):\n",
    "    \"\"\" This function will calculate the neural network predicted output.\n",
    "    The neural network must be trained first.\n",
    "    \n",
    "    Inputs: \n",
    "    test_input - list containing unnormalized parameter values\n",
    "    neural_coeffs - Neural network weights, stored in neural_model.npz file\n",
    "    \n",
    "    Output: Neural network abundance prediction\n",
    "    \"\"\"\n",
    "    \n",
    "    w_array_0,w_array_1,b_array_0,b_array_1 = neural_coeffs\n",
    "    \n",
    "    widths = \n",
    "    norm_data = [item/a.width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO**\n",
    "- Vary optimizer, ReLU function, L1Loss to see which gives best results\n",
    "- Plot loss function against epoch\n",
    "- Plot accuracy on verification dataset against epoch\n",
    "- Vary learning_rate\n",
    "- Plot accuracy on test data as 2D coloured plot in parameter space for each pair\n",
    "\n",
    "**MUST change the predictions to output in NON normalized space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
